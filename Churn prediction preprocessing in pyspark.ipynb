{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.driver.memory\", \"32g\")\n",
    "spark.conf.set(\"spark.executor.memory\", \"32g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "post_schema = StructType([StructField(\"PostId\", StringType(), True), \n",
    "                            StructField(\"PostTypeId\", StringType(), True),\n",
    "                            StructField(\"AcceptedAnswerId\", StringType(), True),\n",
    "                            StructField(\"CreationDate\", TimestampType(), True),\n",
    "                            StructField(\"Score\", DoubleType(), True),\n",
    "                            StructField(\"OwnerUserId\", StringType(), True),\n",
    "                            StructField(\"AnswerCount\", DoubleType(), True),\n",
    "                            StructField(\"CommentCount\", DoubleType(), True),\n",
    "                            StructField(\"ParentId\", StringType(), True),\n",
    "                            StructField(\"CreationDateOfOwner\", TimestampType(), True),\n",
    "                            StructField(\"BodyWordNum\", DoubleType(), True)])\n",
    "                            \n",
    "user_schema = StructType([StructField(\"Id\", StringType(), True), \n",
    "                            StructField(\"CreationDate\", TimestampType(), True),\n",
    "                            StructField(\"isChurn\", BooleanType(), False)])                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "PATH = \"file:///input/project/\"\n",
    "#posts_dist.csv  users_train_dist.csv  users_val_dist.csv\n",
    "post_df = spark.read.format(\"csv\").option(\"header\",\"true\").schema(post_schema).load(PATH + \"posts_dist.csv\")\n",
    "user_train = spark.read.format(\"csv\").option(\"header\",\"true\").schema(user_schema).load(PATH + \"users_train_dist.csv\")\n",
    "user_val = spark.read.format(\"csv\").option(\"header\",\"true\").schema(user_schema).load(PATH + \"users_val_dist.csv\")\n",
    "user_test = spark.read.format(\"csv\").option(\"header\",\"true\").schema(user_schema).load(\"file:///home/ss00/users_test_dist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "post_df.printSchema()\n",
    "user_train.printSchema()\n",
    "user_val.printSchema()\n",
    "user_test.printSchema()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "user_train_df = user_train.withColumn('label', user_train['IsChurn'].cast(IntegerType()))\n",
    "user_train_df = user_train_df.withColumn('data_type', F.lit('train'))\n",
    "user_val_df = user_val.withColumn('label', user_val['IsChurn'].cast(IntegerType()))\n",
    "user_val_df = user_val_df.withColumn('data_type', F.lit('val'))\n",
    "user_test_df = user_test.withColumn('label', user_test['IsChurn'].cast(IntegerType()))\n",
    "user_test_df = user_test_df.withColumn('data_type', F.lit('test'))\n",
    "\n",
    "user_train_val_test = user_train_df.union(user_val_df).union(user_test_df)\n",
    "user_train_val_test = user_train_val_test.withColumnRenamed(\"CreationDate\", \"Id_creation_date\")\n",
    "\n",
    "post_df = post_df.withColumnRenamed(\"OwnerUserId\", \"Id\")\n",
    "post_df = post_df.withColumn('AcceptedAnswerId', post_df['AcceptedAnswerId'].cast(IntegerType()))\n",
    "post_df = post_df.withColumn('AcceptedAnswerId', post_df['AcceptedAnswerId'].cast(StringType()))\n",
    "\n",
    "post_df = post_df.withColumn('ParentId', post_df['ParentId'].cast(IntegerType()))\n",
    "post_df = post_df.withColumn('ParentId', post_df['ParentId'].cast(StringType()))\n",
    "post_df = post_df.withColumnRenamed(\"CreationDate\", \"Post_creation_date\").withColumnRenamed(\"CreationDateOfOwner\", \"Id_creation_date\")\n",
    "post_df = post_df.withColumn('diff_post_id_creation', F.datediff(F.col('Post_creation_date'), F.col('Id_creation_date')))\n",
    "post_df.show()\n",
    "\n",
    "user_train_val_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "print(\"Train user distinct cnt: \", user_train_df.select(\"ID\").distinct().count())\n",
    "print(\"Val user distinct cnt: \", user_val_df.select(\"ID\").distinct().count())\n",
    "print(\"Test user distinct cnt: \", user_test_df.select(\"ID\").distinct().count())\n",
    "print(\"Train & Val user distinct cnt: \", user_train_val_test.select(\"ID\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "user_train_val_test.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "post_df.select('Id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the total ID column from post_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_1 = post_df.select('Id').distinct()\n",
    "print(\"row_num: \" , result_1.count())\n",
    "result_1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add label from train_val_test_df and drop the null values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_1 = result_1.join(user_train_val_test,['Id'], how = 'left').select('Id', 'label', 'data_type')\n",
    "result_1 = result_1.filter(result_1['label'].isNotNull() == True)\n",
    "result_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_1.groupBy('data_Type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - total number of questions by user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30) ).groupBy('Id').agg(F.countDistinct(\"PostId\").alias('post_cnt')).orderBy('post_cnt', ascending=False)\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_2 = result_1.join(query, ['Id'], how = 'left')\n",
    "print(\"null val cnt: \", result_2.filter(result_2['post_cnt'].isNotNull() == False).count())\n",
    "result_2 = result_2.fillna(0, subset=['post_cnt'])\n",
    "print(\"row_num: \" , result_2.count())\n",
    "print(\"null val cnt: \", result_2.filter(result_2['post_cnt'].isNotNull() == False).count())\n",
    "result_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - total or avg number of having the answer for the questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "answ_created_dt = post_df.filter(post_df['PostTypeId'] == 2).select('ParentId', 'PostId', 'Post_creation_date').dropDuplicates() \\\n",
    "                            .withColumnRenamed(\"Post_creation_date\", \"A_Post_creation_date\") \\\n",
    "                            .withColumnRenamed(\"ParentId\", \"A_ParentId\") \\\n",
    "                            .withColumnRenamed(\"PostId\", \"A_PostId\")\n",
    "answ_created_dt.orderBy('A_ParentId').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "question_created_dt = post_df.filter(post_df['PostTypeId'] == 1)\n",
    "question_created_dt_merged = question_created_dt.join(answ_created_dt, question_created_dt['PostId'] == answ_created_dt['A_ParentId'], how = 'inner')\n",
    "question_created_dt_merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "question_created_dt_merged = question_created_dt_merged.withColumn('Aswr_id_created_date_diff', F.datediff(question_created_dt_merged['A_Post_creation_date'], question_created_dt_merged['Id_creation_date']))\n",
    "question_created_dt_merged.orderBy('PostId').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = question_created_dt_merged.filter((question_created_dt_merged['Aswr_id_created_date_diff'] <= 30) & \n",
    "                                            (question_created_dt_merged['diff_post_id_creation'] <= 30)) \\\n",
    "                                            .groupBy('Id').agg(F.countDistinct('A_PostId').alias('ttl_answ_cnt_30days'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_3 = result_2.join(query, ['Id'], how = 'left')\n",
    "result_3 = result_3.fillna(0, subset=['ttl_answ_cnt_30days'])\n",
    "print(\"row_num: \" , result_3.count())\n",
    "print(\"null val cnt: \", result_3.filter(result_3['ttl_answ_cnt_30days'].isNotNull() == False).count())\n",
    "result_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - avg / min / max number of having the answer for the questions ******* 30일동안 받은 게시물 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = question_created_dt_merged.groupBy(['Id', 'PostId']).agg(F.countDistinct('A_PostId').alias('A_post_cnt')).groupBy(['Id']).agg(F.min('A_post_cnt').alias('min_answ_cnt_30days'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_4 = result_3.join(query, ['Id'], how = 'left')\n",
    "result_4 = result_4.fillna(0, subset=['min_answ_cnt_30days'])\n",
    "print(\"row_num: \" , result_4.count())\n",
    "print(\"null val cnt: \", result_4.filter(result_4['min_answ_cnt_30days'].isNotNull() == False).count())\n",
    "result_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = question_created_dt_merged.groupBy(['Id', 'PostId']).agg(F.countDistinct('A_PostId').alias('A_post_cnt')).groupBy(['Id']).agg(F.max('A_post_cnt').alias('max_answ_cnt_30days'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_5 = result_4.join(query, ['Id'], how = 'left')\n",
    "result_5 = result_5.fillna(0, subset=['max_answ_cnt_30days'])\n",
    "print(\"row_num: \" , result_5.count())\n",
    "print(\"null val cnt: \", result_5.filter(result_5['max_answ_cnt_30days'].isNotNull() == False).count())\n",
    "result_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = result_5.withColumn('avg_answ_cnt_30days', result_5['ttl_answ_cnt_30days'] / result_5['post_cnt']).select('Id', 'avg_answ_cnt_30days')\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_6 = result_5.join(query, ['Id'], how = 'left')\n",
    "result_6 = result_6.fillna(0, subset=['avg_answ_cnt_30days'])\n",
    "print(\"row_num: \" , result_6.count())\n",
    "print(\"null val cnt: \", result_6.filter(result_6['avg_answ_cnt_30days'].isNotNull() == False).count())\n",
    "result_6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - total number of having the accepted answer for the questions \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "question_created_dt_merged_filtered = question_created_dt_merged.filter(question_created_dt_merged['AcceptedAnswerId'] == question_created_dt_merged['A_PostId'])\n",
    "question_created_dt_merged_filtered.orderBy('PostId').show()\n",
    "print(question_created_dt_merged_filtered.select('PostID').count())\n",
    "print(question_created_dt_merged_filtered.select('PostID').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = question_created_dt_merged_filtered.filter((question_created_dt_merged_filtered['PostTypeId'] == 1) & \n",
    "                                                    (question_created_dt_merged_filtered['AcceptedAnswerId'].isNotNull()) & \n",
    "                                                    (question_created_dt_merged_filtered['diff_post_id_creation'] <= 30) & \n",
    "                                                    (question_created_dt_merged_filtered['Aswr_id_created_date_diff'] <= 30)).groupBy('Id').count().withColumnRenamed('count', 'accepted_answ_cnt')\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_7 = result_6.join(query, ['Id'], how = 'left')\n",
    "result_7 = result_7.fillna(0, subset=['accepted_answ_cnt'])\n",
    "print(\"row_num: \" , result_7.count())\n",
    "print(\"null val cnt: \", result_7.filter(result_7['accepted_answ_cnt'].isNotNull() == False).count())\n",
    "result_7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - avg/min/max/ttl comment cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.avg('CommentCount').alias('avg_comment_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_8 = result_7.join(query, ['Id'], how = 'left')\n",
    "result_8 = result_8.fillna(0, subset=['avg_comment_cnt'])\n",
    "print(\"row_num: \" , result_8.count())\n",
    "print(\"null val cnt: \", result_8.filter(result_8['avg_comment_cnt'].isNotNull() == False).count())\n",
    "result_8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#total\n",
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.sum('CommentCount').alias('ttl_comment_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_9 = result_8.join(query, ['Id'], how = 'left')\n",
    "result_9 = result_9.fillna(0, subset=['ttl_comment_cnt'])\n",
    "print(\"row_num: \" , result_9.count())\n",
    "print(\"null val cnt: \", result_9.filter(result_9['ttl_comment_cnt'].isNotNull() == False).count())\n",
    "result_9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#min\n",
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.min('CommentCount').alias('min_comment_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_10 = result_9.join(query, ['Id'], how = 'left')\n",
    "result_10 = result_10.fillna(0, subset=['min_comment_cnt'])\n",
    "print(\"row_num: \" , result_10.count())\n",
    "print(\"null val cnt: \", result_10.filter(result_10['min_comment_cnt'].isNotNull() == False).count())\n",
    "result_10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#max\n",
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.max('CommentCount').alias('max_comment_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_11 = result_10.join(query, ['Id'], how = 'left')\n",
    "result_11 = result_11.fillna(0, subset=['max_comment_cnt'])\n",
    "print(\"row_num: \" , result_11.count())\n",
    "print(\"null val cnt: \", result_11.filter(result_11['max_comment_cnt'].isNotNull() == False).count())\n",
    "result_11.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - avg / max / min / ttl score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.avg('Score').alias('q_avg_score'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_12 = result_11.join(query, ['Id'], how = 'left')\n",
    "result_12 = result_12.fillna(0, subset=['q_avg_score'])\n",
    "print(\"row_num: \" , result_12.count())\n",
    "print(\"null val cnt: \", result_12.filter(result_12['q_avg_score'].isNotNull() == False).count())\n",
    "result_12.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.max('Score').alias('q_max_score'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_13 = result_12.join(query, ['Id'], how = 'left')\n",
    "result_13 = result_13.fillna(0, subset=['q_max_score'])\n",
    "print(\"row_num: \" , result_13.count())\n",
    "print(\"null val cnt: \", result_13.filter(result_13['q_max_score'].isNotNull() == False).count())\n",
    "result_13.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.min('Score').alias('q_min_score'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_14 = result_13.join(query, ['Id'], how = 'left')\n",
    "result_14 = result_14.fillna(0, subset=['q_min_score'])\n",
    "print(\"row_num: \" , result_14.count())\n",
    "print(\"null val cnt: \", result_14.filter(result_14['q_min_score'].isNotNull() == False).count())\n",
    "result_14.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.sum('Score').alias('q_ttl_score'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_15 = result_14.join(query, ['Id'], how = 'left')\n",
    "result_15 = result_15.fillna(0, subset=['q_ttl_score'])\n",
    "print(\"row_num: \" , result_15.count())\n",
    "print(\"null val cnt: \", result_15.filter(result_15['q_ttl_score'].isNotNull() == False).count())\n",
    "result_15.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - avg / max / min / ttl body words in the questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#avg\n",
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.avg('BodyWordNum').alias('q_avg_bdword'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_16 = result_15.join(query, ['Id'], how = 'left')\n",
    "result_16 = result_16.fillna(0, subset=['q_avg_bdword'])\n",
    "print(\"row_num: \" , result_16.count())\n",
    "print(\"null val cnt: \", result_16.filter(result_16['q_avg_bdword'].isNotNull() == False).count())\n",
    "result_16.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#max\n",
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.max('BodyWordNum').alias('q_max_bdword'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_17 = result_16.join(query, ['Id'], how = 'left')\n",
    "result_17 = result_17.fillna(0, subset=['q_max_bdword'])\n",
    "print(\"row_num: \" , result_17.count())\n",
    "print(\"null val cnt: \", result_17.filter(result_17['q_max_bdword'].isNotNull() == False).count())\n",
    "result_17.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#min\n",
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.min('BodyWordNum').alias('q_min_bdword'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_18 = result_17.join(query, ['Id'], how = 'left')\n",
    "result_18 = result_18.fillna(0, subset=['q_min_bdword'])\n",
    "print(\"row_num: \" , result_18.count())\n",
    "print(\"null val cnt: \", result_18.filter(result_18['q_min_bdword'].isNotNull() == False).count())\n",
    "result_18.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#ttl\n",
    "query = post_df.filter((post_df['PostTypeId'] == 1) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.sum('BodyWordNum').alias('q_ttl_bdword'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_19 = result_18.join(query, ['Id'], how = 'left')\n",
    "result_19 = result_19.fillna(0, subset=['q_ttl_bdword'])\n",
    "print(\"row_num: \" , result_19.count())\n",
    "print(\"null val cnt: \", result_19.filter(result_19['q_ttl_bdword'].isNotNull() == False).count())\n",
    "result_19.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer - the number of giving answers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 2) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.countDistinct('PostID').alias('answ_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_20 = result_19.join(query, ['Id'], how = 'left')\n",
    "result_20 = result_20.fillna(0, subset=['answ_cnt'])\n",
    "print(\"row_num: \" , result_20.count())\n",
    "print(\"null val cnt: \", result_20.filter(result_20['answ_cnt'].isNotNull() == False).count())\n",
    "result_20.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 9\n",
    "### Answer - the number of accepted answers among the giving answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "question_accepted_id = post_df.filter(post_df['PostTypeId'] == 1).select(\"AcceptedAnswerId\").dropDuplicates()\n",
    "answer_for_post_id = post_df.filter((post_df['PostTypeId'] == 2) & (post_df['diff_post_id_creation'] <= 30)).select(\"PostId\", \"Id\").dropDuplicates()\n",
    "\n",
    "accepted_answer_for_id = question_accepted_id.join(answer_for_post_id, question_accepted_id['AcceptedAnswerId'] == answer_for_post_id[\"PostId\"], how = 'inner') \\\n",
    "                                                .groupBy('Id').agg(F.countDistinct(\"PostId\").alias('accepted_answer_cnt_by_qner'))\n",
    "accepted_answer_for_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_21 = result_20.join(accepted_answer_for_id, ['Id'], how = 'left')\n",
    "result_21 = result_21.fillna(0, subset=['accepted_answer_cnt_by_qner'])\n",
    "print(\"null val cnt: \", result_21.filter(result_21['accepted_answer_cnt_by_qner'].isNotNull() == False).count())\n",
    "print(\"row_num: \" , result_21.count())\n",
    "print(\"null val cnt: \", result_21.filter(result_21['accepted_answer_cnt_by_qner'].isNotNull() == False).count())\n",
    "result_21.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_21.repartition(1).write.format('csv').mode(\"overwrite\").save(\"file:///home/ss00/churn_prj/data1\",header = 'true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 10\n",
    "### Answer - avg/ttl/min/max bodyword count in answers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 2) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.avg('BodyWordNum').alias('avg_answ_bdword_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_22 = result_1.join(query, ['Id'], how = 'left')\n",
    "result_22 = result_22.fillna(0, subset=['avg_answ_bdword_cnt'])\n",
    "print(\"row_num: \" , result_22.count())\n",
    "print(\"null val cnt: \", result_22.filter(result_22['avg_answ_bdword_cnt'].isNotNull() == False).count())\n",
    "result_22.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 2) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.max('BodyWordNum').alias('max_answ_bdword_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_23 = result_22.join(query, ['Id'], how = 'left')\n",
    "result_23 = result_23.fillna(0, subset=['max_answ_bdword_cnt'])\n",
    "print(\"row_num: \" , result_23.count())\n",
    "print(\"null val cnt: \", result_23.filter(result_23['max_answ_bdword_cnt'].isNotNull() == False).count())\n",
    "result_23.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 2) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.min('BodyWordNum').alias('min_answ_bdword_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_24 = result_23.join(query, ['Id'], how = 'left')\n",
    "result_24 = result_24.fillna(0, subset=['min_answ_bdword_cnt'])\n",
    "print(\"row_num: \" , result_24.count())\n",
    "# print(\"null val cnt: \", result_24.filter(result_24['min_answ_bdword_cnt'].isNotNull() == False).count())\n",
    "result_24.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = post_df.filter((post_df['PostTypeId'] == 2) & (post_df['diff_post_id_creation'] <= 30)).groupBy('Id').agg(F.sum('BodyWordNum').alias('ttl_answ_bdword_cnt'))\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_25 = result_24.join(query, ['Id'], how = 'left')\n",
    "result_25 = result_25.fillna(0, subset=['ttl_answ_bdword_cnt'])\n",
    "print(\"row_num: \" , result_25.count())\n",
    "# print(\"null val cnt: \", result_25.filter(result_25['ttl_answ_bdword_cnt'].isNotNull() == False).count())\n",
    "result_25.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post and answer creation interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "post_df_lag = post_df.filter(post_df['diff_post_id_creation'] <= 30) \\\n",
    "                        .withColumn('lag_creation_date',F.lag(post_df['Post_creation_date']).over(Window.partitionBy(\"Id\").orderBy(F.col(\"Post_creation_date\").desc())))\n",
    "post_df_lag = post_df_lag.withColumn('lag_creation_date_final', F.when(post_df_lag['lag_creation_date'].isNull(), F.date_add(post_df_lag['Id_creation_date'], 30)).otherwise(post_df_lag['lag_creation_date']))\n",
    "post_df_lag = post_df_lag.withColumn('post_answer_interval', F.datediff(post_df_lag['lag_creation_date_final'], post_df_lag['Post_creation_date']))\n",
    "\n",
    "post_df_lag.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "result_26 = post_df_lag.filter(post_df_lag['diff_post_id_creation'] <= 30).groupBy('Id').agg(F.avg('post_answer_interval').alias('avg_post_answer_interval'))\n",
    "result_27 = post_df_lag.filter(post_df_lag['diff_post_id_creation'] <= 30).groupBy('Id').agg(F.min('post_answer_interval').alias('min_post_answer_interval'))\n",
    "result_28 = post_df_lag.filter(post_df_lag['diff_post_id_creation'] <= 30).groupBy('Id').agg(F.max('post_answer_interval').alias('max_post_answer_interval'))\n",
    "result_28.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "merged = result_25.join(result_26, ['Id'], how = 'left')\n",
    "merged = merged.fillna(30, subset=['avg_post_answer_interval'])\n",
    "print(\"row_num: \" , merged.count())\n",
    "print(\"null val cnt: \", merged.filter(merged['avg_post_answer_interval'].isNotNull() == False).count())\n",
    "merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "merged = merged.join(result_27, ['Id'], how = 'left')\n",
    "merged = merged.fillna(30, subset=['min_post_answer_interval'])\n",
    "print(\"row_num: \" , merged.count())\n",
    "print(\"null val cnt: \", merged.filter(merged['min_post_answer_interval'].isNotNull() == False).count())\n",
    "merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "merged = merged.join(result_28, ['Id'], how = 'left')\n",
    "merged = merged.fillna(30, subset=['max_post_answer_interval'])\n",
    "print(\"row_num: \" , merged.count())\n",
    "print(\"null val cnt: \", merged.filter(merged['max_post_answer_interval'].isNotNull() == False).count())\n",
    "merged.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last_anw_post_dt_time_passed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "last_post_answ_df = post_df.filter(post_df['diff_post_id_creation'] <= 30).groupBy('Id').agg(F.max('Post_creation_date').alias('last_post_answer_dt'))\n",
    "id_thirtyday_passed_dt = post_df.withColumn('id_thirtyday_passed_dt', F.date_add(post_df['Id_creation_date'], 30)).groupBy('Id').agg(F.max('id_thirtyday_passed_dt').alias('id_thirtyday_passed_dt'))\n",
    "time_passed_df = id_thirtyday_passed_dt.join(last_post_answ_df,['Id'],how = 'inner').withColumn('last_anw_post_dt_time_passed', F.datediff(F.col('id_thirtyday_passed_dt'), F.col('last_post_answer_dt'))).select('Id', 'last_anw_post_dt_time_passed')\n",
    "time_passed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "merged = merged.join(time_passed_df, ['Id'], how = 'left')\n",
    "print(\"null val cnt: \", merged.filter(merged['last_anw_post_dt_time_passed'].isNotNull() == False).count())\n",
    "merged = merged.fillna(30, subset=['last_anw_post_dt_time_passed'])\n",
    "print(\"row_num: \" , merged.count())\n",
    "print(\"null val cnt: \", merged.filter(merged['last_anw_post_dt_time_passed'].isNotNull() == False).count())\n",
    "merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "merged.repartition(1).write.format('csv').mode(\"overwrite\").save(\"file:///home/ss00/churn_prj/data2\",header = 'true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data1 and data2 will be merged in the jupyter notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
